{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from deepmatcher.data.custom_dataset import DeepMatcherDataset\n",
    "from deepmatcher.data.encoder.text_encoders import HFTextEncoder\n",
    "from deepmatcher.optim import Optimizer\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from deepmatcher.models.core import MatchingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (323, 18)\n",
      "val: (108, 18)\n",
      "test: (323, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>left_Song_Name</th>\n",
       "      <th>left_Artist_Name</th>\n",
       "      <th>left_Album_Name</th>\n",
       "      <th>left_Genre</th>\n",
       "      <th>left_Price</th>\n",
       "      <th>left_CopyRight</th>\n",
       "      <th>left_Time</th>\n",
       "      <th>left_Released</th>\n",
       "      <th>right_Song_Name</th>\n",
       "      <th>right_Artist_Name</th>\n",
       "      <th>right_Album_Name</th>\n",
       "      <th>right_Genre</th>\n",
       "      <th>right_Price</th>\n",
       "      <th>right_CopyRight</th>\n",
       "      <th>right_Time</th>\n",
       "      <th>right_Released</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "      <td>Baby When the Light ( David Guetta &amp; Fred Rist...</td>\n",
       "      <td>David Guetta</td>\n",
       "      <td>Pop Life ( Extended Version ) [ Bonus Version ]</td>\n",
       "      <td>Dance , Music , Rock , Pop , House , Electroni...</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>‰ ãÑ 2007 Gum Records</td>\n",
       "      <td>6:17</td>\n",
       "      <td>18-Sep-07</td>\n",
       "      <td>Revolver ( Madonna Vs. David Guetta Feat . Lil...</td>\n",
       "      <td>David Guetta</td>\n",
       "      <td>One Love ( Deluxe Version )</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>( C ) 2014 Swedish House Mafia Holdings Ltd ( ...</td>\n",
       "      <td>3:18</td>\n",
       "      <td>August 21 , 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>Outversion</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>Version</td>\n",
       "      <td>Pop , Music , R&amp;B / Soul,Soul,Dance,Rock,Jazz,...</td>\n",
       "      <td>$ 0.99</td>\n",
       "      <td>2007 Mark Ronson under exclusive license to SO...</td>\n",
       "      <td>1:50</td>\n",
       "      <td>10-Jul-07</td>\n",
       "      <td>Outversion</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>Version [ Explicit ]</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$ 0.99</td>\n",
       "      <td>( c ) 2011 J'adore Records</td>\n",
       "      <td>1:50</td>\n",
       "      <td>July 10 , 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>Peer Pressure ( feat . Traci Nelson )</td>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>Doggumentary</td>\n",
       "      <td>Hip-Hop/Rap , Music , Rock , Gangsta Rap , Wes...</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>‰ ãÑ 2011 Capitol Records , LLC . All rights r...</td>\n",
       "      <td>4:07</td>\n",
       "      <td>29-Mar-11</td>\n",
       "      <td>Boom ( ( Feat . T-Pain ) [ Edited ] )</td>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>Doggumentary [ Edited ]</td>\n",
       "      <td>Rap &amp; Hip-Hop , West Coast</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>( C ) 2011 Capitol Records , LLC</td>\n",
       "      <td>3:50</td>\n",
       "      <td>March 29 , 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>Stars Come Out ( Tim Mason Remix )</td>\n",
       "      <td>Zedd</td>\n",
       "      <td>Stars Come Out ( Remixes ) - EP</td>\n",
       "      <td>Dance , Music , Electronic , House</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>2012 Dim Mak Inc.</td>\n",
       "      <td>5:49</td>\n",
       "      <td>20-May-14</td>\n",
       "      <td>Stars Come Out ( Dillon Francis Remix )</td>\n",
       "      <td>Zedd</td>\n",
       "      <td>Stars Come Out [ Dillon Francis Remix ]</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>2012 Dim Mak Inc.</td>\n",
       "      <td>4:08</td>\n",
       "      <td>May 20 , 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>Jump ( feat . Nelly Furtado )</td>\n",
       "      <td>Flo Rida</td>\n",
       "      <td>R.O.O.T.S. ( Deluxe Version )</td>\n",
       "      <td>Hip-Hop/Rap , Music</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>‰ ãÑ 2009 Atlantic Recording Corporation for t...</td>\n",
       "      <td>3:28</td>\n",
       "      <td>30-Mar-09</td>\n",
       "      <td>Yayo [ Feat . Brisco , Billy Blue , Ball Greez...</td>\n",
       "      <td>Flo Rida</td>\n",
       "      <td>R.O.O.T.S. ( Route Of Overcoming The Struggle ...</td>\n",
       "      <td>Rap &amp; Hip-Hop</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>( C ) 2012 Motown Records , a Division of UMG ...</td>\n",
       "      <td>7:53</td>\n",
       "      <td>March 30 , 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                     left_Song_Name  \\\n",
       "0  448      0  Baby When the Light ( David Guetta & Fred Rist...   \n",
       "1  287      1                                         Outversion   \n",
       "2  534      0              Peer Pressure ( feat . Traci Nelson )   \n",
       "3  181      1                 Stars Come Out ( Tim Mason Remix )   \n",
       "4  485      0                      Jump ( feat . Nelly Furtado )   \n",
       "\n",
       "  left_Artist_Name                                  left_Album_Name  \\\n",
       "0     David Guetta  Pop Life ( Extended Version ) [ Bonus Version ]   \n",
       "1      Mark Ronson                                          Version   \n",
       "2       Snoop Dogg                                     Doggumentary   \n",
       "3             Zedd                  Stars Come Out ( Remixes ) - EP   \n",
       "4         Flo Rida                    R.O.O.T.S. ( Deluxe Version )   \n",
       "\n",
       "                                          left_Genre left_Price  \\\n",
       "0  Dance , Music , Rock , Pop , House , Electroni...     $ 1.29   \n",
       "1  Pop , Music , R&B / Soul,Soul,Dance,Rock,Jazz,...     $ 0.99   \n",
       "2  Hip-Hop/Rap , Music , Rock , Gangsta Rap , Wes...     $ 1.29   \n",
       "3                 Dance , Music , Electronic , House     $ 1.29   \n",
       "4                                Hip-Hop/Rap , Music     $ 1.29   \n",
       "\n",
       "                                      left_CopyRight left_Time left_Released  \\\n",
       "0                              ‰ ãÑ 2007 Gum Records      6:17     18-Sep-07   \n",
       "1  2007 Mark Ronson under exclusive license to SO...      1:50     10-Jul-07   \n",
       "2  ‰ ãÑ 2011 Capitol Records , LLC . All rights r...      4:07     29-Mar-11   \n",
       "3                                  2012 Dim Mak Inc.      5:49     20-May-14   \n",
       "4  ‰ ãÑ 2009 Atlantic Recording Corporation for t...      3:28     30-Mar-09   \n",
       "\n",
       "                                     right_Song_Name right_Artist_Name  \\\n",
       "0  Revolver ( Madonna Vs. David Guetta Feat . Lil...      David Guetta   \n",
       "1                                         Outversion       Mark Ronson   \n",
       "2              Boom ( ( Feat . T-Pain ) [ Edited ] )        Snoop Dogg   \n",
       "3            Stars Come Out ( Dillon Francis Remix )              Zedd   \n",
       "4  Yayo [ Feat . Brisco , Billy Blue , Ball Greez...          Flo Rida   \n",
       "\n",
       "                                    right_Album_Name  \\\n",
       "0                        One Love ( Deluxe Version )   \n",
       "1                               Version [ Explicit ]   \n",
       "2                            Doggumentary [ Edited ]   \n",
       "3            Stars Come Out [ Dillon Francis Remix ]   \n",
       "4  R.O.O.T.S. ( Route Of Overcoming The Struggle ...   \n",
       "\n",
       "                  right_Genre right_Price  \\\n",
       "0          Dance & Electronic      $ 1.29   \n",
       "1                         Pop      $ 0.99   \n",
       "2  Rap & Hip-Hop , West Coast      $ 1.29   \n",
       "3          Dance & Electronic      $ 1.29   \n",
       "4               Rap & Hip-Hop      $ 1.29   \n",
       "\n",
       "                                     right_CopyRight right_Time  \\\n",
       "0  ( C ) 2014 Swedish House Mafia Holdings Ltd ( ...       3:18   \n",
       "1                         ( c ) 2011 J'adore Records       1:50   \n",
       "2                   ( C ) 2011 Capitol Records , LLC       3:50   \n",
       "3                                  2012 Dim Mak Inc.       4:08   \n",
       "4  ( C ) 2012 Motown Records , a Division of UMG ...       7:53   \n",
       "\n",
       "     right_Released  \n",
       "0  August 21 , 2009  \n",
       "1    July 10 , 2007  \n",
       "2   March 29 , 2011  \n",
       "3     May 20 , 2014  \n",
       "4   March 30 , 2009  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = \"sample_data/itunes-amazon/\"\n",
    "train_df = pd.read_csv(os.path.join(dataset_dir, 'train.csv'))\n",
    "print('train:', train_df.shape)\n",
    "val_df = pd.read_csv(os.path.join(dataset_dir, 'validation.csv'))\n",
    "print('val:', val_df.shape)\n",
    "test_df = pd.read_csv(os.path.join(dataset_dir, 'train.csv'))\n",
    "print('test:', test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformer = HFTextEncoder('sentence-transformers/paraphrase-albert-small-v2', max_length=16, truncation=True, padding='max_length', trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received data_df : (323, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 323 entries, 0 to 322\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 323 non-null    int64 \n",
      " 1   label              323 non-null    int64 \n",
      " 2   left_Song_Name     323 non-null    object\n",
      " 3   left_Artist_Name   323 non-null    object\n",
      " 4   left_Album_Name    323 non-null    object\n",
      " 5   left_Genre         323 non-null    object\n",
      " 6   left_Price         323 non-null    object\n",
      " 7   left_CopyRight     323 non-null    object\n",
      " 8   left_Time          323 non-null    object\n",
      " 9   left_Released      312 non-null    object\n",
      " 10  right_Song_Name    323 non-null    object\n",
      " 11  right_Artist_Name  323 non-null    object\n",
      " 12  right_Album_Name   323 non-null    object\n",
      " 13  right_Genre        323 non-null    object\n",
      " 14  right_Price        323 non-null    object\n",
      " 15  right_CopyRight    323 non-null    object\n",
      " 16  right_Time         323 non-null    object\n",
      " 17  right_Released     321 non-null    object\n",
      "dtypes: int64(2), object(16)\n",
      "memory usage: 45.5+ KB\n",
      "supplied text columns : Song_Name, Artist_Name, Album_Name, Genre, Price, CopyRight, Time, Released\n",
      "supplied image column : \n",
      "supplied label column : label\n",
      "received data_df : (108, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108 entries, 0 to 107\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 108 non-null    int64 \n",
      " 1   label              108 non-null    int64 \n",
      " 2   left_Song_Name     108 non-null    object\n",
      " 3   left_Artist_Name   108 non-null    object\n",
      " 4   left_Album_Name    108 non-null    object\n",
      " 5   left_Genre         108 non-null    object\n",
      " 6   left_Price         108 non-null    object\n",
      " 7   left_CopyRight     108 non-null    object\n",
      " 8   left_Time          108 non-null    object\n",
      " 9   left_Released      103 non-null    object\n",
      " 10  right_Song_Name    108 non-null    object\n",
      " 11  right_Artist_Name  108 non-null    object\n",
      " 12  right_Album_Name   108 non-null    object\n",
      " 13  right_Genre        108 non-null    object\n",
      " 14  right_Price        108 non-null    object\n",
      " 15  right_CopyRight    108 non-null    object\n",
      " 16  right_Time         108 non-null    object\n",
      " 17  right_Released     105 non-null    object\n",
      "dtypes: int64(2), object(16)\n",
      "memory usage: 15.3+ KB\n",
      "supplied text columns : Song_Name, Artist_Name, Album_Name, Genre, Price, CopyRight, Time, Released\n",
      "supplied image column : \n",
      "supplied label column : label\n",
      "received data_df : (323, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 323 entries, 0 to 322\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 323 non-null    int64 \n",
      " 1   label              323 non-null    int64 \n",
      " 2   left_Song_Name     323 non-null    object\n",
      " 3   left_Artist_Name   323 non-null    object\n",
      " 4   left_Album_Name    323 non-null    object\n",
      " 5   left_Genre         323 non-null    object\n",
      " 6   left_Price         323 non-null    object\n",
      " 7   left_CopyRight     323 non-null    object\n",
      " 8   left_Time          323 non-null    object\n",
      " 9   left_Released      312 non-null    object\n",
      " 10  right_Song_Name    323 non-null    object\n",
      " 11  right_Artist_Name  323 non-null    object\n",
      " 12  right_Album_Name   323 non-null    object\n",
      " 13  right_Genre        323 non-null    object\n",
      " 14  right_Price        323 non-null    object\n",
      " 15  right_CopyRight    323 non-null    object\n",
      " 16  right_Time         323 non-null    object\n",
      " 17  right_Released     321 non-null    object\n",
      "dtypes: int64(2), object(16)\n",
      "memory usage: 45.5+ KB\n",
      "supplied text columns : Song_Name, Artist_Name, Album_Name, Genre, Price, CopyRight, Time, Released\n",
      "supplied image column : \n",
      "supplied label column : label\n"
     ]
    }
   ],
   "source": [
    "label_column = 'label'\n",
    "text_columns = ['Song_Name', 'Artist_Name', 'Album_Name', 'Genre', 'Price', 'CopyRight', 'Time', 'Released']\n",
    "image_col = ''\n",
    "tokenizer = text_transformer.tokenizer\n",
    "\n",
    "train_dataset = DeepMatcherDataset(\n",
    "    data_df=train_df,\n",
    "    label_col=label_column,\n",
    "    text_cols=text_columns,\n",
    "    image_col=image_col,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = DeepMatcherDataset(\n",
    "    data_df=val_df,\n",
    "    label_col=label_column,\n",
    "    text_cols=text_columns,\n",
    "    image_col=image_col,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = DeepMatcherDataset(\n",
    "    data_df=test_df,\n",
    "    label_col=label_column,\n",
    "    text_cols=text_columns,\n",
    "    image_col=image_col,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attrs': defaultdict(dict,\n",
       "             {'Song_Name': {'left_': {'input_ids': tensor([   2, 1578,   76,   14,  471,   13,    5,  684, 4835, 8232,  279, 4250,\n",
       "                         761, 9959, 5039,    3]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       "               'right_': {'input_ids': tensor([    2, 18497,    13,     5, 12257,  4611,     9,   684,  4835,  8232,\n",
       "                         9806,    13,     9,  9672,    13,     3]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}},\n",
       "              'Artist_Name': {'left_': {'input_ids': tensor([   2,  684, 4835, 8232,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([   2,  684, 4835, 8232,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}},\n",
       "              'Album_Name': {'left_': {'input_ids': tensor([   2, 1675,  201,   13,    5, 1984,  615,   13,    6,  636, 5708,  615,\n",
       "                          13,  500,    3,    0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])},\n",
       "               'right_': {'input_ids': tensor([    2,    53,   339,    13,     5, 18172,   615,    13,     6,     3,\n",
       "                            0,     0,     0,     0,     0,     0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0])}},\n",
       "              'Genre': {'left_': {'input_ids': tensor([   2, 1329,   13,   15,  232,   13,   15,  629,   13,   15, 1675,   13,\n",
       "                          15,  191,   13,    3]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       "               'right_': {'input_ids': tensor([   2, 1329,  279, 3253,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}},\n",
       "              'Price': {'left_': {'input_ids': tensor([   2, 5579,  137,    9, 2738,    3,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([   2, 5579,  137,    9, 2738,    3,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}},\n",
       "              'CopyRight': {'left_': {'input_ids': tensor([    2,    13,     1,    40,   624, 10150,   742,     3,     0,     0,\n",
       "                            0,     0,     0,     0,     0,     0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([    2,    13,     5,   272,    13,     6,   623,  3061,   191, 16065,\n",
       "                        10916,  3706,    13,     5,   334,     3]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}},\n",
       "              'Time': {'left_': {'input_ids': tensor([   2, 9523, 1053,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([   2, 2635, 1087,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}},\n",
       "              'Released': {'left_': {'input_ids': tensor([   2,  474,    8,   18, 3492,    8, 2984,    3,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([  2, 316, 852,  13,  15, 588,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "                          0,   0]),\n",
       "                'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])}}}),\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataset:\n",
    "    break\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attrs']['Song_Name']['left_']['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatchingModel(\n",
    "    text_encoder=text_transformer,\n",
    "    attr_summarizer=None,\n",
    "    attr_condense_factor='auto',\n",
    "    attr_comparator='concat',\n",
    "    attr_merge='concat',\n",
    "    classifier='2-layer-highway',\n",
    "    hidden_size=300\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchingModel(\n",
       "  (text_encoder): HFTextEncoder(\n",
       "    (model): AlbertModel(\n",
       "      (embeddings): AlbertEmbeddings(\n",
       "        (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (encoder): AlbertTransformer(\n",
       "        (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "        (albert_layer_groups): ModuleList(\n",
       "          (0): AlbertLayerGroup(\n",
       "            (albert_layers): ModuleList(\n",
       "              (0): AlbertLayer(\n",
       "                (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (attention): AlbertAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                  (output_dropout): Dropout(p=0, inplace=False)\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                )\n",
       "                (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (pooler_activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\installations\\anaconda\\envs\\aisle3-torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MatchingModel(\n",
       "  (text_encoder): HFTextEncoder(\n",
       "    (model): AlbertModel(\n",
       "      (embeddings): AlbertEmbeddings(\n",
       "        (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (encoder): AlbertTransformer(\n",
       "        (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "        (albert_layer_groups): ModuleList(\n",
       "          (0): AlbertLayerGroup(\n",
       "            (albert_layers): ModuleList(\n",
       "              (0): AlbertLayer(\n",
       "                (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (attention): AlbertAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                  (output_dropout): Dropout(p=0, inplace=False)\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                )\n",
       "                (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (pooler_activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (attr_condensors): ModuleMap(\n",
       "    (Song_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Genre): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Price): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Time): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Released): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_comparators): ModuleMap(\n",
       "    (Song_Name): Merge()\n",
       "    (Artist_Name): Merge()\n",
       "    (Album_Name): Merge()\n",
       "    (Genre): Merge()\n",
       "    (Price): Merge()\n",
       "    (CopyRight): Merge()\n",
       "    (Time): Merge()\n",
       "    (Released): Merge()\n",
       "  )\n",
       "  (attr_comparator): Merge()\n",
       "  (attr_merge): Merge()\n",
       "  (classifier): Classifier(\n",
       "    (transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=800, out_features=300, bias=True)\n",
       "        (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=800, out_features=300, bias=True)\n",
       "        )\n",
       "        (1): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax_transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): None\n",
       "      )\n",
       "    )\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_batch = next(iter(DataLoader(train_dataset, batch_size=2)))['attrs'] ## draw a batch to initialize the lazy model \n",
    "model.initialize(train_dataset, init_batch=init_batch)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(lr=1e-3, lr_decay=1e-1, start_decay_at=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 12960586\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\installations\\anaconda\\envs\\aisle3-torch\\lib\\site-packages\\torch\\nn\\functional.py:2741: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:    8.4 | Load Time:    0.3 || F1:  21.57 | Prec:  44.00 | Rec:  14.29 || Ex/s:  37.26\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:    2.2 | Load Time:    0.2 || F1:  51.43 | Prec:  81.82 | Rec:  37.50 || Ex/s:  44.72\n",
      "\n",
      "Updating Learning Rate: 8.000e-04 Acc: 51.42856979370117 Epoch: 1\n",
      "* Best F1: tensor(51.4286, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:    6.5 | Load Time:    0.3 || F1:  67.20 | Prec:  87.50 | Rec:  54.55 || Ex/s:  47.40\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:    2.2 | Load Time:    0.1 || F1:  65.22 | Prec:  68.18 | Rec:  62.50 || Ex/s:  46.78\n",
      "\n",
      "Updating Learning Rate: 6.400e-04 Acc: 65.2173843383789 Epoch: 2\n",
      "* Best F1: tensor(65.2174, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:    6.6 | Load Time:    0.3 || F1:  82.43 | Prec:  85.92 | Rec:  79.22 || Ex/s:  46.69\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:    2.2 | Load Time:    0.1 || F1:  73.47 | Prec:  72.00 | Rec:  75.00 || Ex/s:  46.15\n",
      "\n",
      "Updating Learning Rate: 5.120e-04 Acc: 73.46939086914062 Epoch: 3\n",
      "* Best F1: tensor(73.4694, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    6.6 | Load Time:    0.3 || F1:  92.62 | Prec:  95.83 | Rec:  89.61 || Ex/s:  46.78\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    2.2 | Load Time:    0.1 || F1:  72.34 | Prec:  73.91 | Rec:  70.83 || Ex/s:  46.75\n",
      "\n",
      "Updating Learning Rate: 4.096e-04 Acc: 72.3404312133789 Epoch: 4\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:    6.5 | Load Time:    0.3 || F1:  96.64 | Prec: 100.00 | Rec:  93.51 || Ex/s:  47.23\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:    2.2 | Load Time:    0.1 || F1:  72.34 | Prec:  73.91 | Rec:  70.83 || Ex/s:  46.16\n",
      "\n",
      "Updating Learning Rate: 3.277e-04 Acc: 72.3404312133789 Epoch: 5\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:    6.8 | Load Time:    0.3 || F1:  99.35 | Prec:  98.72 | Rec: 100.00 || Ex/s:  45.40\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:    2.2 | Load Time:    0.1 || F1:  73.91 | Prec:  77.27 | Rec:  70.83 || Ex/s:  46.85\n",
      "\n",
      "Updating Learning Rate: 2.621e-04 Acc: 73.91304016113281 Epoch: 6\n",
      "* Best F1: tensor(73.9130, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:    6.6 | Load Time:    0.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  46.83\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:    2.3 | Load Time:    0.1 || F1:  71.11 | Prec:  76.19 | Rec:  66.67 || Ex/s:  44.62\n",
      "\n",
      "Updating Learning Rate: 2.097e-04 Acc: 71.1111068725586 Epoch: 7\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:    6.5 | Load Time:    0.3 || F1:  99.35 | Prec: 100.00 | Rec:  98.70 || Ex/s:  47.12\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:    2.1 | Load Time:    0.1 || F1:  69.57 | Prec:  72.73 | Rec:  66.67 || Ex/s:  47.54\n",
      "\n",
      "Updating Learning Rate: 1.678e-04 Acc: 69.5652084350586 Epoch: 8\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:    6.5 | Load Time:    0.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  47.22\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:    2.2 | Load Time:    0.1 || F1:  69.57 | Prec:  72.73 | Rec:  66.67 || Ex/s:  47.38\n",
      "\n",
      "Updating Learning Rate: 1.342e-04 Acc: 69.5652084350586 Epoch: 9\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:    6.5 | Load Time:    0.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  47.65\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:    2.2 | Load Time:    0.1 || F1:  69.57 | Prec:  72.73 | Rec:  66.67 || Ex/s:  47.55\n",
      "\n",
      "Updating Learning Rate: 1.074e-04 Acc: 69.5652084350586 Epoch: 10\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 11 || Run Time:    7.1 | Load Time:    0.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  43.73\n",
      "\n",
      "===>  EVAL Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 11 || Run Time:    2.3 | Load Time:    0.1 || F1:  72.34 | Prec:  73.91 | Rec:  70.83 || Ex/s:  44.39\n",
      "\n",
      "Updating Learning Rate: 8.590e-05 Acc: 72.3404312133789 Epoch: 11\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 12 || Run Time:    6.5 | Load Time:    0.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  47.37\n",
      "\n",
      "===>  EVAL Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 12 || Run Time:    2.2 | Load Time:    0.1 || F1:  69.57 | Prec:  72.73 | Rec:  66.67 || Ex/s:  47.41\n",
      "\n",
      "Updating Learning Rate: 6.872e-05 Acc: 69.5652084350586 Epoch: 12\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 13 || Run Time:    6.6 | Load Time:    0.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  46.47\n",
      "\n",
      "===>  EVAL Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 13 || Run Time:    2.2 | Load Time:    0.1 || F1:  69.57 | Prec:  72.73 | Rec:  66.67 || Ex/s:  47.69\n",
      "\n",
      "Updating Learning Rate: 5.498e-05 Acc: 69.5652084350586 Epoch: 13\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 14 || Run Time:    6.6 | Load Time:    0.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  46.50\n",
      "\n",
      "===>  EVAL Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 14 || Run Time:    2.2 | Load Time:    0.1 || F1:  69.57 | Prec:  72.73 | Rec:  66.67 || Ex/s:  47.36\n",
      "\n",
      "Updating Learning Rate: 4.398e-05 Acc: 69.5652084350586 Epoch: 14\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 15 || Run Time:    6.6 | Load Time:    0.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  46.90\n",
      "\n",
      "===>  EVAL Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 15 || Run Time:    2.3 | Load Time:    0.1 || F1:  72.34 | Prec:  73.91 | Rec:  70.83 || Ex/s:  43.77\n",
      "\n",
      "Updating Learning Rate: 3.518e-05 Acc: 72.3404312133789 Epoch: 15\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(73.9130, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.run_train(\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    best_save_path='best_mode.pth',\n",
    "    batch_size=16,\n",
    "    epochs=15,\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_eval(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
