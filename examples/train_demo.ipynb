{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul  5 22:23:53 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 461.33       Driver Version: 461.33       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1650   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   44C    P8     3W /  N/A |    624MiB /  4096MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1408    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      3524    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      3876    C+G   ...bbwe\\HxCalendarAppImm.exe    N/A      |\n",
      "|    0   N/A  N/A      4920    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A      6920    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      8304    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A      9016    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     10052    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
      "|    0   N/A  N/A     10300    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10724    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11552    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     12476    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     12736    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12912    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     13616    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     15696    C+G   ..._dt26b99r8h8gj\\RtkUWP.exe    N/A      |\n",
      "|    0   N/A  N/A     15720    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     25580    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from deepmatcher.data.custom_dataset import DeepMatcherDataset\n",
    "from deepmatcher.data.encoder.text_encoders import HFTextEncoder\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from deepmatcher.models.core import MatchingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (323, 18)\n",
      "val: (108, 18)\n",
      "test: (323, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>left_Song_Name</th>\n",
       "      <th>left_Artist_Name</th>\n",
       "      <th>left_Album_Name</th>\n",
       "      <th>left_Genre</th>\n",
       "      <th>left_Price</th>\n",
       "      <th>left_CopyRight</th>\n",
       "      <th>left_Time</th>\n",
       "      <th>left_Released</th>\n",
       "      <th>right_Song_Name</th>\n",
       "      <th>right_Artist_Name</th>\n",
       "      <th>right_Album_Name</th>\n",
       "      <th>right_Genre</th>\n",
       "      <th>right_Price</th>\n",
       "      <th>right_CopyRight</th>\n",
       "      <th>right_Time</th>\n",
       "      <th>right_Released</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "      <td>Baby When the Light ( David Guetta &amp; Fred Rist...</td>\n",
       "      <td>David Guetta</td>\n",
       "      <td>Pop Life ( Extended Version ) [ Bonus Version ]</td>\n",
       "      <td>Dance , Music , Rock , Pop , House , Electroni...</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>‰ ãÑ 2007 Gum Records</td>\n",
       "      <td>6:17</td>\n",
       "      <td>18-Sep-07</td>\n",
       "      <td>Revolver ( Madonna Vs. David Guetta Feat . Lil...</td>\n",
       "      <td>David Guetta</td>\n",
       "      <td>One Love ( Deluxe Version )</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>( C ) 2014 Swedish House Mafia Holdings Ltd ( ...</td>\n",
       "      <td>3:18</td>\n",
       "      <td>August 21 , 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>Outversion</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>Version</td>\n",
       "      <td>Pop , Music , R&amp;B / Soul,Soul,Dance,Rock,Jazz,...</td>\n",
       "      <td>$ 0.99</td>\n",
       "      <td>2007 Mark Ronson under exclusive license to SO...</td>\n",
       "      <td>1:50</td>\n",
       "      <td>10-Jul-07</td>\n",
       "      <td>Outversion</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>Version [ Explicit ]</td>\n",
       "      <td>Pop</td>\n",
       "      <td>$ 0.99</td>\n",
       "      <td>( c ) 2011 J'adore Records</td>\n",
       "      <td>1:50</td>\n",
       "      <td>July 10 , 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>Peer Pressure ( feat . Traci Nelson )</td>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>Doggumentary</td>\n",
       "      <td>Hip-Hop/Rap , Music , Rock , Gangsta Rap , Wes...</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>‰ ãÑ 2011 Capitol Records , LLC . All rights r...</td>\n",
       "      <td>4:07</td>\n",
       "      <td>29-Mar-11</td>\n",
       "      <td>Boom ( ( Feat . T-Pain ) [ Edited ] )</td>\n",
       "      <td>Snoop Dogg</td>\n",
       "      <td>Doggumentary [ Edited ]</td>\n",
       "      <td>Rap &amp; Hip-Hop , West Coast</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>( C ) 2011 Capitol Records , LLC</td>\n",
       "      <td>3:50</td>\n",
       "      <td>March 29 , 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>Stars Come Out ( Tim Mason Remix )</td>\n",
       "      <td>Zedd</td>\n",
       "      <td>Stars Come Out ( Remixes ) - EP</td>\n",
       "      <td>Dance , Music , Electronic , House</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>2012 Dim Mak Inc.</td>\n",
       "      <td>5:49</td>\n",
       "      <td>20-May-14</td>\n",
       "      <td>Stars Come Out ( Dillon Francis Remix )</td>\n",
       "      <td>Zedd</td>\n",
       "      <td>Stars Come Out [ Dillon Francis Remix ]</td>\n",
       "      <td>Dance &amp; Electronic</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>2012 Dim Mak Inc.</td>\n",
       "      <td>4:08</td>\n",
       "      <td>May 20 , 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>Jump ( feat . Nelly Furtado )</td>\n",
       "      <td>Flo Rida</td>\n",
       "      <td>R.O.O.T.S. ( Deluxe Version )</td>\n",
       "      <td>Hip-Hop/Rap , Music</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>‰ ãÑ 2009 Atlantic Recording Corporation for t...</td>\n",
       "      <td>3:28</td>\n",
       "      <td>30-Mar-09</td>\n",
       "      <td>Yayo [ Feat . Brisco , Billy Blue , Ball Greez...</td>\n",
       "      <td>Flo Rida</td>\n",
       "      <td>R.O.O.T.S. ( Route Of Overcoming The Struggle ...</td>\n",
       "      <td>Rap &amp; Hip-Hop</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>( C ) 2012 Motown Records , a Division of UMG ...</td>\n",
       "      <td>7:53</td>\n",
       "      <td>March 30 , 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                     left_Song_Name  \\\n",
       "0  448      0  Baby When the Light ( David Guetta & Fred Rist...   \n",
       "1  287      1                                         Outversion   \n",
       "2  534      0              Peer Pressure ( feat . Traci Nelson )   \n",
       "3  181      1                 Stars Come Out ( Tim Mason Remix )   \n",
       "4  485      0                      Jump ( feat . Nelly Furtado )   \n",
       "\n",
       "  left_Artist_Name                                  left_Album_Name  \\\n",
       "0     David Guetta  Pop Life ( Extended Version ) [ Bonus Version ]   \n",
       "1      Mark Ronson                                          Version   \n",
       "2       Snoop Dogg                                     Doggumentary   \n",
       "3             Zedd                  Stars Come Out ( Remixes ) - EP   \n",
       "4         Flo Rida                    R.O.O.T.S. ( Deluxe Version )   \n",
       "\n",
       "                                          left_Genre left_Price  \\\n",
       "0  Dance , Music , Rock , Pop , House , Electroni...     $ 1.29   \n",
       "1  Pop , Music , R&B / Soul,Soul,Dance,Rock,Jazz,...     $ 0.99   \n",
       "2  Hip-Hop/Rap , Music , Rock , Gangsta Rap , Wes...     $ 1.29   \n",
       "3                 Dance , Music , Electronic , House     $ 1.29   \n",
       "4                                Hip-Hop/Rap , Music     $ 1.29   \n",
       "\n",
       "                                      left_CopyRight left_Time left_Released  \\\n",
       "0                              ‰ ãÑ 2007 Gum Records      6:17     18-Sep-07   \n",
       "1  2007 Mark Ronson under exclusive license to SO...      1:50     10-Jul-07   \n",
       "2  ‰ ãÑ 2011 Capitol Records , LLC . All rights r...      4:07     29-Mar-11   \n",
       "3                                  2012 Dim Mak Inc.      5:49     20-May-14   \n",
       "4  ‰ ãÑ 2009 Atlantic Recording Corporation for t...      3:28     30-Mar-09   \n",
       "\n",
       "                                     right_Song_Name right_Artist_Name  \\\n",
       "0  Revolver ( Madonna Vs. David Guetta Feat . Lil...      David Guetta   \n",
       "1                                         Outversion       Mark Ronson   \n",
       "2              Boom ( ( Feat . T-Pain ) [ Edited ] )        Snoop Dogg   \n",
       "3            Stars Come Out ( Dillon Francis Remix )              Zedd   \n",
       "4  Yayo [ Feat . Brisco , Billy Blue , Ball Greez...          Flo Rida   \n",
       "\n",
       "                                    right_Album_Name  \\\n",
       "0                        One Love ( Deluxe Version )   \n",
       "1                               Version [ Explicit ]   \n",
       "2                            Doggumentary [ Edited ]   \n",
       "3            Stars Come Out [ Dillon Francis Remix ]   \n",
       "4  R.O.O.T.S. ( Route Of Overcoming The Struggle ...   \n",
       "\n",
       "                  right_Genre right_Price  \\\n",
       "0          Dance & Electronic      $ 1.29   \n",
       "1                         Pop      $ 0.99   \n",
       "2  Rap & Hip-Hop , West Coast      $ 1.29   \n",
       "3          Dance & Electronic      $ 1.29   \n",
       "4               Rap & Hip-Hop      $ 1.29   \n",
       "\n",
       "                                     right_CopyRight right_Time  \\\n",
       "0  ( C ) 2014 Swedish House Mafia Holdings Ltd ( ...       3:18   \n",
       "1                         ( c ) 2011 J'adore Records       1:50   \n",
       "2                   ( C ) 2011 Capitol Records , LLC       3:50   \n",
       "3                                  2012 Dim Mak Inc.       4:08   \n",
       "4  ( C ) 2012 Motown Records , a Division of UMG ...       7:53   \n",
       "\n",
       "     right_Released  \n",
       "0  August 21 , 2009  \n",
       "1    July 10 , 2007  \n",
       "2   March 29 , 2011  \n",
       "3     May 20 , 2014  \n",
       "4   March 30 , 2009  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = \"examples/sample_data/itunes-amazon/\"\n",
    "train_df = pd.read_csv(os.path.join(dataset_dir, 'train.csv'))\n",
    "print('train:', train_df.shape)\n",
    "val_df = pd.read_csv(os.path.join(dataset_dir, 'validation.csv'))\n",
    "print('val:', val_df.shape)\n",
    "test_df = pd.read_csv(os.path.join(dataset_dir, 'train.csv'))\n",
    "print('test:', test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "text_transformer = HFTextEncoder('distilbert-base-uncased', max_length=16, truncation=True, padding='max_length', trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received data_df : (323, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 323 entries, 0 to 322\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 323 non-null    int64 \n",
      " 1   label              323 non-null    int64 \n",
      " 2   left_Song_Name     323 non-null    object\n",
      " 3   left_Artist_Name   323 non-null    object\n",
      " 4   left_Album_Name    323 non-null    object\n",
      " 5   left_Genre         323 non-null    object\n",
      " 6   left_Price         323 non-null    object\n",
      " 7   left_CopyRight     323 non-null    object\n",
      " 8   left_Time          323 non-null    object\n",
      " 9   left_Released      312 non-null    object\n",
      " 10  right_Song_Name    323 non-null    object\n",
      " 11  right_Artist_Name  323 non-null    object\n",
      " 12  right_Album_Name   323 non-null    object\n",
      " 13  right_Genre        323 non-null    object\n",
      " 14  right_Price        323 non-null    object\n",
      " 15  right_CopyRight    323 non-null    object\n",
      " 16  right_Time         323 non-null    object\n",
      " 17  right_Released     321 non-null    object\n",
      "dtypes: int64(2), object(16)\n",
      "memory usage: 45.5+ KB\n",
      "supplied text columns : Song_Name, Artist_Name, Album_Name, Genre, Price, CopyRight, Time, Released\n",
      "supplied image column : \n",
      "supplied label column : label\n",
      "received data_df : (108, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108 entries, 0 to 107\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 108 non-null    int64 \n",
      " 1   label              108 non-null    int64 \n",
      " 2   left_Song_Name     108 non-null    object\n",
      " 3   left_Artist_Name   108 non-null    object\n",
      " 4   left_Album_Name    108 non-null    object\n",
      " 5   left_Genre         108 non-null    object\n",
      " 6   left_Price         108 non-null    object\n",
      " 7   left_CopyRight     108 non-null    object\n",
      " 8   left_Time          108 non-null    object\n",
      " 9   left_Released      103 non-null    object\n",
      " 10  right_Song_Name    108 non-null    object\n",
      " 11  right_Artist_Name  108 non-null    object\n",
      " 12  right_Album_Name   108 non-null    object\n",
      " 13  right_Genre        108 non-null    object\n",
      " 14  right_Price        108 non-null    object\n",
      " 15  right_CopyRight    108 non-null    object\n",
      " 16  right_Time         108 non-null    object\n",
      " 17  right_Released     105 non-null    object\n",
      "dtypes: int64(2), object(16)\n",
      "memory usage: 15.3+ KB\n",
      "supplied text columns : Song_Name, Artist_Name, Album_Name, Genre, Price, CopyRight, Time, Released\n",
      "supplied image column : \n",
      "supplied label column : label\n",
      "received data_df : (323, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 323 entries, 0 to 322\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 323 non-null    int64 \n",
      " 1   label              323 non-null    int64 \n",
      " 2   left_Song_Name     323 non-null    object\n",
      " 3   left_Artist_Name   323 non-null    object\n",
      " 4   left_Album_Name    323 non-null    object\n",
      " 5   left_Genre         323 non-null    object\n",
      " 6   left_Price         323 non-null    object\n",
      " 7   left_CopyRight     323 non-null    object\n",
      " 8   left_Time          323 non-null    object\n",
      " 9   left_Released      312 non-null    object\n",
      " 10  right_Song_Name    323 non-null    object\n",
      " 11  right_Artist_Name  323 non-null    object\n",
      " 12  right_Album_Name   323 non-null    object\n",
      " 13  right_Genre        323 non-null    object\n",
      " 14  right_Price        323 non-null    object\n",
      " 15  right_CopyRight    323 non-null    object\n",
      " 16  right_Time         323 non-null    object\n",
      " 17  right_Released     321 non-null    object\n",
      "dtypes: int64(2), object(16)\n",
      "memory usage: 45.5+ KB\n",
      "supplied text columns : Song_Name, Artist_Name, Album_Name, Genre, Price, CopyRight, Time, Released\n",
      "supplied image column : \n",
      "supplied label column : label\n"
     ]
    }
   ],
   "source": [
    "label_column = 'label'\n",
    "text_columns = ['Song_Name', 'Artist_Name', 'Album_Name', 'Genre', 'Price', 'CopyRight', 'Time', 'Released']\n",
    "image_col = ''\n",
    "tokenizer = text_transformer.tokenizer\n",
    "\n",
    "train_dataset = DeepMatcherDataset(\n",
    "    data_df=train_df,\n",
    "    label_col=label_column,\n",
    "    text_cols=text_columns,\n",
    "    image_col=image_col,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = DeepMatcherDataset(\n",
    "    data_df=val_df,\n",
    "    label_col=label_column,\n",
    "    text_cols=text_columns,\n",
    "    image_col=image_col,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = DeepMatcherDataset(\n",
    "    data_df=test_df,\n",
    "    label_col=label_column,\n",
    "    text_cols=text_columns,\n",
    "    image_col=image_col,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attrs': defaultdict(dict,\n",
       "             {'Song_Name': {'left_': {'input_ids': tensor([  101,  3336,  2043,  1996,  2422,  1006,  2585, 19739, 16549,  1004,\n",
       "                         5965, 15544,  6238,  6136,  1007,   102]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       "               'right_': {'input_ids': tensor([  101, 17863,  1006, 11284,  5443,  1012,  2585, 19739, 16549,  8658,\n",
       "                         1012, 13451,  1005,  6159,  1007,   102]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}},\n",
       "              'Artist_Name': {'left_': {'input_ids': tensor([  101,  2585, 19739, 16549,   102,     0,     0,     0,     0,     0,\n",
       "                            0,     0,     0,     0,     0,     0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([  101,  2585, 19739, 16549,   102,     0,     0,     0,     0,     0,\n",
       "                            0,     0,     0,     0,     0,     0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}},\n",
       "              'Album_Name': {'left_': {'input_ids': tensor([ 101, 3769, 2166, 1006, 3668, 2544, 1007, 1031, 6781, 2544, 1033,  102,\n",
       "                           0,    0,    0,    0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([  101,  2028,  2293,  1006, 15203,  2544,  1007,   102,     0,     0,\n",
       "                            0,     0,     0,     0,     0,     0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])}},\n",
       "              'Genre': {'left_': {'input_ids': tensor([ 101, 3153, 1010, 2189, 1010, 2600, 1010, 3769, 1010, 2160, 1010, 4816,\n",
       "                        1010, 4816, 2050,  102]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       "               'right_': {'input_ids': tensor([ 101, 3153, 1004, 4816,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}},\n",
       "              'Price': {'left_': {'input_ids': tensor([ 101, 1002, 1015, 1012, 2756,  102,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([ 101, 1002, 1015, 1012, 2756,  102,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}},\n",
       "              'CopyRight': {'left_': {'input_ids': tensor([  101,  1530,  2019,  2289, 16031,  2636,   102,     0,     0,     0,\n",
       "                            0,     0,     0,     0,     0,     0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([  101,  1006,  1039,  1007,  2297,  4467,  2160, 13897,  9583,  5183,\n",
       "                         1006,  1038,  5737,  1007,  2104,   102]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}},\n",
       "              'Time': {'left_': {'input_ids': tensor([ 101, 1020, 1024, 2459,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([ 101, 1017, 1024, 2324,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}},\n",
       "              'Released': {'left_': {'input_ids': tensor([  101,  2324,  1011, 19802,  1011,  5718,   102,     0,     0,     0,\n",
       "                            0,     0,     0,     0,     0,     0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       "               'right_': {'input_ids': tensor([ 101, 2257, 2538, 1010, 2268,  102,    0,    0,    0,    0,    0,    0,\n",
       "                           0,    0,    0,    0]),\n",
       "                'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}}}),\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataset:\n",
    "    break\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attrs']['Song_Name']['left_']['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatchingModel(\n",
    "    text_encoder=text_transformer,\n",
    "    attr_summarizer=None,\n",
    "    attr_condense_factor='auto',\n",
    "    attr_comparator='concat',\n",
    "    attr_merge='concat',\n",
    "    classifier='2-layer-highway',\n",
    "    hidden_size=300\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchingModel(\n",
       "  (text_encoder): HFTextEncoder(\n",
       "    (model): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\installations\\anaconda\\envs\\aisle3-torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MatchingModel(\n",
       "  (text_encoder): HFTextEncoder(\n",
       "    (model): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_condensors): ModuleMap(\n",
       "    (Song_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Genre): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Price): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Time): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Released): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_comparators): ModuleMap(\n",
       "    (Song_Name): Merge()\n",
       "    (Artist_Name): Merge()\n",
       "    (Album_Name): Merge()\n",
       "    (Genre): Merge()\n",
       "    (Price): Merge()\n",
       "    (CopyRight): Merge()\n",
       "    (Time): Merge()\n",
       "    (Released): Merge()\n",
       "  )\n",
       "  (attr_comparator): Merge()\n",
       "  (attr_merge): Merge()\n",
       "  (classifier): Classifier(\n",
       "    (transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=800, out_features=300, bias=True)\n",
       "        (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=800, out_features=300, bias=True)\n",
       "        )\n",
       "        (1): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax_transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): None\n",
       "      )\n",
       "    )\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_batch = next(iter(DataLoader(train_dataset, batch_size=2)))['attrs'] ## draw a batch to initialize the lazy model \n",
    "model.initialize(train_dataset, init_batch=init_batch)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 67639882\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\installations\\anaconda\\envs\\aisle3-torch\\lib\\site-packages\\torch\\nn\\functional.py:2741: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:    6.9 | Load Time:    0.3 || F1:   2.38 | Prec:  14.29 | Rec:   1.30 || Ex/s:  44.69\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:    1.6 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:  61.96\n",
      "\n",
      "* Best F1: tensor(0., device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:    5.0 | Load Time:    0.3 || F1:  26.09 | Prec:  80.00 | Rec:  15.58 || Ex/s:  60.80\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:    1.7 | Load Time:    0.1 || F1:  53.66 | Prec:  64.71 | Rec:  45.83 || Ex/s:  61.12\n",
      "\n",
      "* Best F1: tensor(53.6585, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:    4.9 | Load Time:    0.3 || F1:  73.10 | Prec:  77.94 | Rec:  68.83 || Ex/s:  61.76\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:    1.6 | Load Time:    0.1 || F1:  59.09 | Prec:  65.00 | Rec:  54.17 || Ex/s:  62.17\n",
      "\n",
      "* Best F1: tensor(59.0909, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    5.0 | Load Time:    0.3 || F1:  74.65 | Prec:  81.54 | Rec:  68.83 || Ex/s:  60.96\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    1.6 | Load Time:    0.1 || F1:  62.22 | Prec:  66.67 | Rec:  58.33 || Ex/s:  61.09\n",
      "\n",
      "* Best F1: tensor(62.2222, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:    5.0 | Load Time:    0.3 || F1:  74.48 | Prec:  79.41 | Rec:  70.13 || Ex/s:  61.19\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:    1.6 | Load Time:    0.1 || F1:  50.00 | Prec:  75.00 | Rec:  37.50 || Ex/s:  61.86\n",
      "\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(62.2222, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.run_train(\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    best_save_path='best_mode.pth',\n",
    "    batch_size=16,\n",
    "    epochs=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  EVAL Epoch 3\n",
      "/home/sour4bh/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "0% [██] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n",
      "Finished Epoch 3 || Run Time:    4.7 | Load Time:    0.6 || F1:  77.71 | Prec:  76.25 | Rec:  79.22 || Ex/s:  61.52\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(77.7070, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.run_eval(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
