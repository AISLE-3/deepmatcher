{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wed Jul  7 16:54:50 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.42.01    Driver Version: 471.11       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   57C    P8     6W /  N/A |   1344MiB /  6144MiB |    ERR!      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from deepmatcher.data.custom_dataset import DeepMatcherDataset\n",
    "from deepmatcher.data.encoder.text_encoders import HFTextEncoder\n",
    "from deepmatcher.data.encoder.image_encoders import DINOImageEncoder\n",
    "from deepmatcher.optim import Optimizer\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from deepmatcher.models.core import MatchingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train: (323, 18)\nval: (108, 18)\ntest: (323, 18)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    id  label                                     left_Song_Name  \\\n",
       "0  448      0  Baby When the Light ( David Guetta & Fred Rist...   \n",
       "1  287      1                                         Outversion   \n",
       "2  534      0              Peer Pressure ( feat . Traci Nelson )   \n",
       "3  181      1                 Stars Come Out ( Tim Mason Remix )   \n",
       "4  485      0                      Jump ( feat . Nelly Furtado )   \n",
       "\n",
       "  left_Artist_Name                                  left_Album_Name  \\\n",
       "0     David Guetta  Pop Life ( Extended Version ) [ Bonus Version ]   \n",
       "1      Mark Ronson                                          Version   \n",
       "2       Snoop Dogg                                     Doggumentary   \n",
       "3             Zedd                  Stars Come Out ( Remixes ) - EP   \n",
       "4         Flo Rida                    R.O.O.T.S. ( Deluxe Version )   \n",
       "\n",
       "                                          left_Genre left_Price  \\\n",
       "0  Dance , Music , Rock , Pop , House , Electroni...     $ 1.29   \n",
       "1  Pop , Music , R&B / Soul,Soul,Dance,Rock,Jazz,...     $ 0.99   \n",
       "2  Hip-Hop/Rap , Music , Rock , Gangsta Rap , Wes...     $ 1.29   \n",
       "3                 Dance , Music , Electronic , House     $ 1.29   \n",
       "4                                Hip-Hop/Rap , Music     $ 1.29   \n",
       "\n",
       "                                      left_CopyRight left_Time left_Released  \\\n",
       "0                              ‰ ãÑ 2007 Gum Records      6:17     18-Sep-07   \n",
       "1  2007 Mark Ronson under exclusive license to SO...      1:50     10-Jul-07   \n",
       "2  ‰ ãÑ 2011 Capitol Records , LLC . All rights r...      4:07     29-Mar-11   \n",
       "3                                  2012 Dim Mak Inc.      5:49     20-May-14   \n",
       "4  ‰ ãÑ 2009 Atlantic Recording Corporation for t...      3:28     30-Mar-09   \n",
       "\n",
       "                                     right_Song_Name right_Artist_Name  \\\n",
       "0  Revolver ( Madonna Vs. David Guetta Feat . Lil...      David Guetta   \n",
       "1                                         Outversion       Mark Ronson   \n",
       "2              Boom ( ( Feat . T-Pain ) [ Edited ] )        Snoop Dogg   \n",
       "3            Stars Come Out ( Dillon Francis Remix )              Zedd   \n",
       "4  Yayo [ Feat . Brisco , Billy Blue , Ball Greez...          Flo Rida   \n",
       "\n",
       "                                    right_Album_Name  \\\n",
       "0                        One Love ( Deluxe Version )   \n",
       "1                               Version [ Explicit ]   \n",
       "2                            Doggumentary [ Edited ]   \n",
       "3            Stars Come Out [ Dillon Francis Remix ]   \n",
       "4  R.O.O.T.S. ( Route Of Overcoming The Struggle ...   \n",
       "\n",
       "                  right_Genre right_Price  \\\n",
       "0          Dance & Electronic      $ 1.29   \n",
       "1                         Pop      $ 0.99   \n",
       "2  Rap & Hip-Hop , West Coast      $ 1.29   \n",
       "3          Dance & Electronic      $ 1.29   \n",
       "4               Rap & Hip-Hop      $ 1.29   \n",
       "\n",
       "                                     right_CopyRight right_Time  \\\n",
       "0  ( C ) 2014 Swedish House Mafia Holdings Ltd ( ...       3:18   \n",
       "1                         ( c ) 2011 J'adore Records       1:50   \n",
       "2                   ( C ) 2011 Capitol Records , LLC       3:50   \n",
       "3                                  2012 Dim Mak Inc.       4:08   \n",
       "4  ( C ) 2012 Motown Records , a Division of UMG ...       7:53   \n",
       "\n",
       "     right_Released                              left_image  \\\n",
       "0  August 21 , 2009  sample_data/itunes-amazon/test_img.jpg   \n",
       "1    July 10 , 2007  sample_data/itunes-amazon/test_img.jpg   \n",
       "2   March 29 , 2011  sample_data/itunes-amazon/test_img.jpg   \n",
       "3     May 20 , 2014  sample_data/itunes-amazon/test_img.jpg   \n",
       "4   March 30 , 2009  sample_data/itunes-amazon/test_img.jpg   \n",
       "\n",
       "                              right_image  \n",
       "0  sample_data/itunes-amazon/test_img.jpg  \n",
       "1  sample_data/itunes-amazon/test_img.jpg  \n",
       "2  sample_data/itunes-amazon/test_img.jpg  \n",
       "3  sample_data/itunes-amazon/test_img.jpg  \n",
       "4  sample_data/itunes-amazon/test_img.jpg  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>left_Song_Name</th>\n      <th>left_Artist_Name</th>\n      <th>left_Album_Name</th>\n      <th>left_Genre</th>\n      <th>left_Price</th>\n      <th>left_CopyRight</th>\n      <th>left_Time</th>\n      <th>left_Released</th>\n      <th>right_Song_Name</th>\n      <th>right_Artist_Name</th>\n      <th>right_Album_Name</th>\n      <th>right_Genre</th>\n      <th>right_Price</th>\n      <th>right_CopyRight</th>\n      <th>right_Time</th>\n      <th>right_Released</th>\n      <th>left_image</th>\n      <th>right_image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>448</td>\n      <td>0</td>\n      <td>Baby When the Light ( David Guetta &amp; Fred Rist...</td>\n      <td>David Guetta</td>\n      <td>Pop Life ( Extended Version ) [ Bonus Version ]</td>\n      <td>Dance , Music , Rock , Pop , House , Electroni...</td>\n      <td>$ 1.29</td>\n      <td>‰ ãÑ 2007 Gum Records</td>\n      <td>6:17</td>\n      <td>18-Sep-07</td>\n      <td>Revolver ( Madonna Vs. David Guetta Feat . Lil...</td>\n      <td>David Guetta</td>\n      <td>One Love ( Deluxe Version )</td>\n      <td>Dance &amp; Electronic</td>\n      <td>$ 1.29</td>\n      <td>( C ) 2014 Swedish House Mafia Holdings Ltd ( ...</td>\n      <td>3:18</td>\n      <td>August 21 , 2009</td>\n      <td>sample_data/itunes-amazon/test_img.jpg</td>\n      <td>sample_data/itunes-amazon/test_img.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>287</td>\n      <td>1</td>\n      <td>Outversion</td>\n      <td>Mark Ronson</td>\n      <td>Version</td>\n      <td>Pop , Music , R&amp;B / Soul,Soul,Dance,Rock,Jazz,...</td>\n      <td>$ 0.99</td>\n      <td>2007 Mark Ronson under exclusive license to SO...</td>\n      <td>1:50</td>\n      <td>10-Jul-07</td>\n      <td>Outversion</td>\n      <td>Mark Ronson</td>\n      <td>Version [ Explicit ]</td>\n      <td>Pop</td>\n      <td>$ 0.99</td>\n      <td>( c ) 2011 J'adore Records</td>\n      <td>1:50</td>\n      <td>July 10 , 2007</td>\n      <td>sample_data/itunes-amazon/test_img.jpg</td>\n      <td>sample_data/itunes-amazon/test_img.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>534</td>\n      <td>0</td>\n      <td>Peer Pressure ( feat . Traci Nelson )</td>\n      <td>Snoop Dogg</td>\n      <td>Doggumentary</td>\n      <td>Hip-Hop/Rap , Music , Rock , Gangsta Rap , Wes...</td>\n      <td>$ 1.29</td>\n      <td>‰ ãÑ 2011 Capitol Records , LLC . All rights r...</td>\n      <td>4:07</td>\n      <td>29-Mar-11</td>\n      <td>Boom ( ( Feat . T-Pain ) [ Edited ] )</td>\n      <td>Snoop Dogg</td>\n      <td>Doggumentary [ Edited ]</td>\n      <td>Rap &amp; Hip-Hop , West Coast</td>\n      <td>$ 1.29</td>\n      <td>( C ) 2011 Capitol Records , LLC</td>\n      <td>3:50</td>\n      <td>March 29 , 2011</td>\n      <td>sample_data/itunes-amazon/test_img.jpg</td>\n      <td>sample_data/itunes-amazon/test_img.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>181</td>\n      <td>1</td>\n      <td>Stars Come Out ( Tim Mason Remix )</td>\n      <td>Zedd</td>\n      <td>Stars Come Out ( Remixes ) - EP</td>\n      <td>Dance , Music , Electronic , House</td>\n      <td>$ 1.29</td>\n      <td>2012 Dim Mak Inc.</td>\n      <td>5:49</td>\n      <td>20-May-14</td>\n      <td>Stars Come Out ( Dillon Francis Remix )</td>\n      <td>Zedd</td>\n      <td>Stars Come Out [ Dillon Francis Remix ]</td>\n      <td>Dance &amp; Electronic</td>\n      <td>$ 1.29</td>\n      <td>2012 Dim Mak Inc.</td>\n      <td>4:08</td>\n      <td>May 20 , 2014</td>\n      <td>sample_data/itunes-amazon/test_img.jpg</td>\n      <td>sample_data/itunes-amazon/test_img.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>485</td>\n      <td>0</td>\n      <td>Jump ( feat . Nelly Furtado )</td>\n      <td>Flo Rida</td>\n      <td>R.O.O.T.S. ( Deluxe Version )</td>\n      <td>Hip-Hop/Rap , Music</td>\n      <td>$ 1.29</td>\n      <td>‰ ãÑ 2009 Atlantic Recording Corporation for t...</td>\n      <td>3:28</td>\n      <td>30-Mar-09</td>\n      <td>Yayo [ Feat . Brisco , Billy Blue , Ball Greez...</td>\n      <td>Flo Rida</td>\n      <td>R.O.O.T.S. ( Route Of Overcoming The Struggle ...</td>\n      <td>Rap &amp; Hip-Hop</td>\n      <td>$ 1.29</td>\n      <td>( C ) 2012 Motown Records , a Division of UMG ...</td>\n      <td>7:53</td>\n      <td>March 30 , 2009</td>\n      <td>sample_data/itunes-amazon/test_img.jpg</td>\n      <td>sample_data/itunes-amazon/test_img.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataset_dir = \"sample_data/itunes-amazon/\"\n",
    "train_df = pd.read_csv(os.path.join(dataset_dir, 'train.csv'))\n",
    "print('train:', train_df.shape)\n",
    "val_df = pd.read_csv(os.path.join(dataset_dir, 'validation.csv'))\n",
    "print('val:', val_df.shape)\n",
    "test_df = pd.read_csv(os.path.join(dataset_dir, 'train.csv'))\n",
    "print('test:', test_df.shape)\n",
    "\n",
    "for df in (train_df, val_df, test_df):\n",
    "    df['left_image'] = df['right_image'] = os.path.join(dataset_dir, 'test_img.jpg')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.weight', 'predictions.bias', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight']\n- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "text_encoder = HFTextEncoder('albert-base-v2', trainable=False, seqtovec='mean')\n",
    "image_encoder = DINOImageEncoder(device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "received data_df : (323, 20)\nsupplied text columns : Song_Name, Artist_Name, Album_Name, Genre, Price, CopyRight, Time, Released\nsupplied image column : image\nsupplied label column : label\nreceived data_df : (108, 20)\nsupplied text columns : Song_Name, Artist_Name, Album_Name, Genre, Price, CopyRight, Time, Released\nsupplied image column : image\nsupplied label column : label\nreceived data_df : (323, 20)\nsupplied text columns : Song_Name, Artist_Name, Album_Name, Genre, Price, CopyRight, Time, Released\nsupplied image column : image\nsupplied label column : label\n"
     ]
    }
   ],
   "source": [
    "label_column = 'label'\n",
    "text_columns = ['Song_Name', 'Artist_Name', 'Album_Name', 'Genre', 'Price', 'CopyRight', 'Time', 'Released']\n",
    "image_col = 'image'\n",
    "tokenizer = text_encoder.tokenizer\n",
    "\n",
    "def get_dataloader(data_df, label_column, text_cols, imaeg_col, tokenizer, batch_size, shuffle, num_workers):\n",
    "    dataset = DeepMatcherDataset(\n",
    "        data_df=data_df,\n",
    "        label_col=label_column,\n",
    "        text_cols=text_columns,\n",
    "        image_col=image_col,\n",
    "        tokenizer=tokenizer\n",
    "        )\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, collate_fn=dataset.collate_fn)\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "\n",
    "train_dataloader = get_dataloader(train_df, label_column, text_columns, image_col, tokenizer, batch_size, True, num_workers)\n",
    "val_dataloader = get_dataloader(val_df, label_column, text_columns, image_col, tokenizer, batch_size, False, num_workers)\n",
    "test_dataloader = get_dataloader(test_df, label_column, text_columns, image_col, tokenizer, batch_size, False, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text_attrs: ['Song_Name', 'Artist_Name', 'Album_Name', 'Genre', 'Price', 'CopyRight', 'Time', 'Released']\nimage_attr: image\nprefixes: ('left_', 'right_')\nattrs: ['Song_Name', 'Artist_Name', 'Album_Name', 'Genre', 'Price', 'CopyRight', 'Time', 'Released', 'image']\nall attrs: ['left_Song_Name', 'right_Song_Name', 'left_Artist_Name', 'right_Artist_Name', 'left_Album_Name', 'right_Album_Name', 'left_Genre', 'right_Genre', 'left_Price', 'right_Price', 'left_CopyRight', 'right_CopyRight', 'left_Time', 'right_Time', 'left_Released', 'right_Released', 'left_image', 'right_image']\n"
     ]
    }
   ],
   "source": [
    "model = MatchingModel(\n",
    "    text_encoder=text_encoder,\n",
    "    image_encoder=image_encoder,\n",
    "    attr_summarizer=None,\n",
    "    attr_condense_factor='auto',\n",
    "    attr_comparator='concat',\n",
    "    attr_merge='concat',\n",
    "    classifier='2-layer-highway',\n",
    "    hidden_size=300,\n",
    "    text_attrs=text_columns,\n",
    "    image_attr='image'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/sour4bh/.local/lib/python3.8/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/home/sour4bh/.local/lib/python3.8/site-packages/torch/nn/functional.py:3657: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n",
      "/home/sour4bh/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MatchingModel(\n",
       "  (text_encoder): HFTextEncoder(\n",
       "    (model): AlbertModel(\n",
       "      (embeddings): AlbertEmbeddings(\n",
       "        (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 128)\n",
       "        (token_type_embeddings): Embedding(2, 128)\n",
       "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (encoder): AlbertTransformer(\n",
       "        (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "        (albert_layer_groups): ModuleList(\n",
       "          (0): AlbertLayerGroup(\n",
       "            (albert_layers): ModuleList(\n",
       "              (0): AlbertLayer(\n",
       "                (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (attention): AlbertAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                  (output_dropout): Dropout(p=0, inplace=False)\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                )\n",
       "                (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (pooler_activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (attr_condensors): ModuleMap(\n",
       "    (Song_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Genre): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Price): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Time): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Released): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (image): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=768, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_comparators): ModuleMap(\n",
       "    (Song_Name): Merge()\n",
       "    (Artist_Name): Merge()\n",
       "    (Album_Name): Merge()\n",
       "    (Genre): Merge()\n",
       "    (Price): Merge()\n",
       "    (CopyRight): Merge()\n",
       "    (Time): Merge()\n",
       "    (Released): Merge()\n",
       "    (image): Merge()\n",
       "  )\n",
       "  (attr_comparator): Merge()\n",
       "  (attr_merge): Merge()\n",
       "  (classifier): Classifier(\n",
       "    (transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=900, out_features=300, bias=True)\n",
       "        (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=900, out_features=300, bias=True)\n",
       "        )\n",
       "        (1): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax_transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): None\n",
       "      )\n",
       "    )\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model.initialize(next(iter(train_dataloader))['attrs'])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Optimizer(lr=1e-3, lr_decay=1e-1, start_decay_at=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "* Number of trainable parameters: 1413902\n",
      "===>  TRAIN Epoch 1\n",
      "/home/sour4bh/.local/lib/python3.8/site-packages/torch/nn/functional.py:2741: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "0% [████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:21\n",
      "Finished Epoch 1 || Run Time:   81.1 | Load Time:    1.3 || F1:  16.67 | Prec:  42.11 | Rec:  10.39 || Ex/s:   3.92\n",
      "\n",
      "===>  EVAL Epoch 1\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f9639acb3bdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.run_train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbest_save_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best_mode.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/deepmatcher/examples/../deepmatcher/models/core.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mF1\u001b[0m \u001b[0mscore\u001b[0m \u001b[0mobtained\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/deepmatcher/examples/../deepmatcher/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, validation_dataloader, best_save_path, epochs, criterion, optimizer, pos_neg_ratio, pos_weight, label_smoothing, save_every_prefix, save_every_freq, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 'TRAIN', model, train_dataloader, criterion, optimizer, train=True, **kwargs)\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EVAL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/deepmatcher/examples/../deepmatcher/runner.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(run_type, model, dataloader, criterion, optimizer, train, device, batch_size, batch_callback, epoch_callback, progress_style, log_freq, sort_in_buckets, return_predictions, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# from torchviz import make_dot, make_dot_from_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/deepmatcher/examples/../deepmatcher/models/core.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_attr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mattr_comparisons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/deepmatcher/examples/../deepmatcher/data/encoder/image_encoders.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/d/deepmatcher/examples/../deepmatcher/data/encoder/image_encoders.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/deepmatcher/examples/../deepmatcher/data/encoder/image_encoders.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pmcore/core/feature_extraction.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_img_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_file_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pmcore/core/feature_extraction.py\u001b[0m in \u001b[0;36mfrom_binary\u001b[0;34m(self, img, return_original_image, return_attention, return_mask, return_segmentation)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mfeature_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_forward_and_last_selfattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         outputs = {\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.run_train(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    best_save_path='best_mode.pth',\n",
    "    epochs=15,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_eval(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}